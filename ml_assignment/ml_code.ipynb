{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arman\\AppData\\Local\\Temp/ipykernel_6036/992380415.py:8: DtypeWarning: Columns (15,16,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  raw_training_data = load_training_data()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the training data.\n",
    "\"\"\"\n",
    "TRAINING_DATA_PATH = \"./data/train.csv\"\n",
    "def load_training_data(training_data_path=TRAINING_DATA_PATH):\n",
    "    return pd.read_csv(training_data_path)\n",
    "\n",
    "raw_training_data = load_training_data()\n",
    "training_data = raw_training_data.drop(\"label\", axis=1)\n",
    "training_data_labels = raw_training_data[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are non-numeric columns: \n",
      "\tprotocol_type\n",
      "\tservice\n",
      "\tflag\n",
      "\tnum_root\n",
      "\tnum_file_creations\n",
      "\tnum_shells\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sanitize Data\n",
    "\"\"\"\n",
    "# Print all columns that are non-numeric types\n",
    "nan_training_data = training_data.select_dtypes(exclude=[np.number])\n",
    "print(\"The following are non-numeric columns: \")\n",
    "for col in nan_training_data.columns:\n",
    "    print(\"\\t\"+ col)\n",
    "\n",
    "# We know that 'protocol_type', 'service', and 'flag' are simply string\n",
    "# labels, so we map those to integer values first using scikit's OrdinalEncoder.\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "training_data['protocol_type_code'] = ordinal_encoder.fit_transform(\n",
    "    training_data[['protocol_type']]\n",
    ")\n",
    "training_data['service_code'] = ordinal_encoder.fit_transform(\n",
    "    training_data[['service']]\n",
    ")\n",
    "training_data['flag_code'] = ordinal_encoder.fit_transform(\n",
    "    training_data[['flag']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to clean up 'num_root', 'num_file_creations', and 'num_shells'.\n",
    "# We know currently that there are random string entries. To solve this problem,\n",
    "# we will replace those string with 0.\n",
    "\n",
    "# print(training_data['num_root'].value_counts())\n",
    "# print(training_data['num_file_creations'].value_counts())\n",
    "# print(training_data['num_shells'].value_counts())\n",
    "\n",
    "# training_data['num_root'] = np.where(\n",
    "#     training_data['num_root'] == 'tcp', 0, training_data['num_root']\n",
    "# )\n",
    "# training_data['num_file_creations'] = np.where(\n",
    "#     training_data['num_file_creations'] == 'http', 0, training_data['num_file_creations']\n",
    "# )\n",
    "# training_data['num_shells'] = np.where(\n",
    "#     training_data['num_shells'] == 'SF', 0, training_data['num_shells']\n",
    "# )\n",
    "\n",
    "# # Now the ultimate test, convert those features to dtype64\n",
    "training_data[['num_root', 'num_file_creations', 'num_shells']] = training_data[['num_root', 'num_file_creations', 'num_shells']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are non-numeric columns: \n",
      "\tprotocol_type\n",
      "\tservice\n",
      "\tflag\n"
     ]
    }
   ],
   "source": [
    "# View all datatypes present in dataset\n",
    "# Three object types still remain ('protocol_type', 'service', 'flag') \n",
    "# because we left them there in a previous step.\n",
    "\n",
    "nan_training_data = training_data.select_dtypes(exclude=[np.number])\n",
    "print(\"The following are non-numeric columns: \")\n",
    "for col in nan_training_data.columns:\n",
    "    print(\"\\t\"+ col)\n",
    "\n",
    "# training_data.info(show_counts=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a86703512c55a747b3f6aea0bf5e2800f7da673d7d7bbac1ab56d73bfe078da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('snowflakes': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
